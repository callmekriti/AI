{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7DGbuYtB1JI",
        "outputId": "a3ed9a01-e0a5-4f4a-f242-9b12e6c8fdbf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Function for Text Cleaning:\n",
        "\n",
        "Implement a Helper Function as per Text Preprocessing Notebook and Complete the following pipeline."
      ],
      "metadata": {
        "id": "SxV-QBHp-B6J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build a Text Cleaning Pipeline"
      ],
      "metadata": {
        "id": "B-llg-TI_Drw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def remove_urls(data):\n",
        "  \"\"\"\n",
        "  This function will try to remove URL present in out dataset and replace it with space using regex library.\n",
        "  Input Args:\n",
        "  text: strings of text that may contain URLs.\n",
        "  Output Args:\n",
        "  text: URLs replaces with text\n",
        "  \"\"\"\n",
        "  url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "  return url_pattern.sub(r'', data)"
      ],
      "metadata": {
        "id": "snVw3PAcG8Tz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_emoji(string):\n",
        "  \"\"\"\n",
        "  This function will replace the emoji in string with whitespace\n",
        "  \"\"\"\n",
        "  emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "  return emoji_pattern.sub(r' ', string)"
      ],
      "metadata": {
        "id": "m-XcB2VOHJ7H"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_emoji(string):\n",
        "  \"\"\"\n",
        "  This function will replace the emoji in string with whitespace\n",
        "  \"\"\"\n",
        "  emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "  return emoji_pattern.sub(r' ', string)"
      ],
      "metadata": {
        "id": "qFJtzrn0HR4D"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download stopwords if you haven't done so already\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Initialize the stopwords list\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stopwords(text_tokens):\n",
        "    \"\"\"\n",
        "    This function removes all the stopwords present in our text tokens.\n",
        "\n",
        "    Input Args:\n",
        "    text_tokens: List of tokens to process.\n",
        "\n",
        "    Returns:\n",
        "    result_tokens: List of tokens without stopwords.\n",
        "    \"\"\"\n",
        "\n",
        "    result_tokens = [token for token in text_tokens if token not in stop_words]\n",
        "    return result_tokens\n"
      ],
      "metadata": {
        "id": "mmxwUj0oHlCK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fd27802-bf44-4dce-847c-e577bcc1fb5d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def removeunwanted_characters(document):\n",
        "  \"\"\"\n",
        "  This function will remove all the unwanted characters from the input dataset.\n",
        "  Input Args:\n",
        "  documet: A text data to be cleaned.\n",
        "  Return:\n",
        "  A cleaned document.\n",
        "  \"\"\"\n",
        "  # remove user mentions\n",
        "  document = re.sub(\"@[A-Za-z0-9_]+\",\" \", document)\n",
        "  # remove hashtags\n",
        "  document = re.sub(\"#[A-Za-z0-9_]+\",\"\", document)\n",
        "  # remove punctuation\n",
        "  document = re.sub(\"[^0-9A-Za-z ]\", \"\" , document)\n",
        "  #remove emojis\n",
        "  document = remove_emoji(document)\n",
        "  # remove double spaces\n",
        "  document = document.replace('  ',\"\")\n",
        "  return document.strip()"
      ],
      "metadata": {
        "id": "KIMtPFbu7sxA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import word_tokenize,pos_tag\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def lemmatization(token_text):\n",
        "  \"\"\"\n",
        "  This function performs the lemmatization operations as explained above.\n",
        "  Input Args:\n",
        "  token_text: list of tokens.\n",
        "  Returns:\n",
        "  lemmatized_tokens: list of lemmatized tokens.\n",
        "  \"\"\"\n",
        "  lemma_tokens = []\n",
        "  wordnet = WordNetLemmatizer()\n",
        "  lemmatized_tokens = [wordnet.lemmatize(token, pos = 'v') for token in token_text]\n",
        "\n",
        "  return lemmatized_tokens"
      ],
      "metadata": {
        "id": "d8oKTY5uHumD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81a3126d-213f-47de-b12a-dad31aa60b54"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "def stemming(text):\n",
        "  \"\"\"\n",
        "  This function performs stemming operations.\n",
        "  Input Args:\n",
        "  token_text: list of tokenize text.\n",
        "  Returns:\n",
        "  stemm_tokes: list of stemmed tokens.\n",
        "  \"\"\"\n",
        "  porter = PorterStemmer()\n",
        "  stemm_tokens = []\n",
        "  for word in text:\n",
        "    stemm_tokens.append(porter.stem(word))\n",
        "  return stemm_tokens"
      ],
      "metadata": {
        "id": "0Lkk-VqrH4zH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_cleaning_pipeline(dataset, rule = \"lemmatize\"):\n",
        "    \"\"\"\n",
        "    This...\n",
        "    \"\"\"\n",
        "    # Initialize 'data' with the input 'dataset'\n",
        "    data = dataset\n",
        "\n",
        "    # Convert the input to small/lower order.\n",
        "    data = data.lower()\n",
        "\n",
        "    # Remove URLs\n",
        "    data = remove_urls(data)\n",
        "\n",
        "    # Remove emojis\n",
        "    data = remove_emoji(data)\n",
        "\n",
        "    # Remove all other unwanted characters.\n",
        "    data = removeunwanted_characters(data)\n",
        "\n",
        "    # Create tokens.\n",
        "    tokens = data.split()\n",
        "\n",
        "    # Remove stopwords:\n",
        "    tokens = remove_stopwords(tokens)\n",
        "\n",
        "    # Apply lemmatization or stemming based on the rule\n",
        "    if rule == \"lemmatize\":\n",
        "        tokens = lemmatization(tokens)  # No need to split here\n",
        "    elif rule == \"stem\":\n",
        "        tokens = stemming(tokens)\n",
        "    else:\n",
        "        print(\"Pick between lemmatize or stem\")\n",
        "\n",
        "    return \" \".join(tokens)"
      ],
      "metadata": {
        "id": "KCT1T3-68tN9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Classification using Machine Learning Models\n"
      ],
      "metadata": {
        "id": "hzMm4-1KCNkH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìù Instructions: Trump Tweet Sentiment Classification\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n",
        "\n",
        "\n",
        "1. **Load the Dataset**  \n",
        "   Load the dataset named `\"trump_tweet_sentiment_analysis.csv\"` using `pandas`. Ensure the dataset contains at least two columns: `\"text\"` and `\"label\"`.\n",
        "\n",
        "2. **Text Cleaning and Tokenization**  \n",
        "   Apply a text preprocessing pipeline to the `\"text\"` column. This should include:\n",
        "   - Lowercasing the text  \n",
        "   - Removing URLs, mentions, punctuation, and special characters  \n",
        "   - Removing stopwords  \n",
        "   - Tokenization (optional: stemming or lemmatization)\n",
        "   - \"Complete the above function\"\n",
        "\n",
        "3. **Train-Test Split**  \n",
        "   Split the cleaned and tokenized dataset into **training** and **testing** sets using `train_test_split` from `sklearn.model_selection`.\n",
        "\n",
        "4. **TF-IDF Vectorization**  \n",
        "   Import and use the `TfidfVectorizer` from `sklearn.feature_extraction.text` to transform the training and testing texts into numerical feature vectors.\n",
        "\n",
        "5. **Model Training and Evaluation**  \n",
        "   Import **Logistic Regression** (or any machine learning model of your choice) from `sklearn.linear_model`. Train it on the TF-IDF-embedded training data, then evaluate it using the test set.  \n",
        "   - Print the **classification report** using `classification_report` from `sklearn.metrics`.\n"
      ],
      "metadata": {
        "id": "oFltIxr9L2Wu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "qkQxPqcwKAIg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/AI/trum_tweet_sentiment_analysis.csv')"
      ],
      "metadata": {
        "id": "cnwKqXrAKA2A"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Cleaning and Tokenization"
      ],
      "metadata": {
        "id": "IvvWh03s-sQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[['text']].dropna()"
      ],
      "metadata": {
        "id": "P4cLWs4aKQgw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "ed6f157c-39c2-4aba-e22b-e66b8aee7213"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                      text\n",
              "0        RT @JohnLeguizamo: #trump not draining swamp b...\n",
              "1        ICYMI: Hackers Rig FM Radio Stations To Play A...\n",
              "2        Trump protests: LGBTQ rally in New York https:...\n",
              "3        \"Hi I'm Piers Morgan. David Beckham is awful b...\n",
              "4        RT @GlennFranco68: Tech Firm Suing BuzzFeed fo...\n",
              "...                                                    ...\n",
              "1850118  Everytime im like 'How the fuck I follow Melan...\n",
              "1850119  RT @imgur: The Trump Handshake. https://t.co/R...\n",
              "1850120  \"Greenspan warns Trump's policies risk inflati...\n",
              "1850121  RT @FasinatingLogic: We must also #INVESTIGATE...\n",
              "1850122  RT @imgur: The Trump Handshake. https://t.co/R...\n",
              "\n",
              "[1850123 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0767cb9e-e9f7-4ce2-97ea-2b6d46d636d2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RT @JohnLeguizamo: #trump not draining swamp b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ICYMI: Hackers Rig FM Radio Stations To Play A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Trump protests: LGBTQ rally in New York https:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"Hi I'm Piers Morgan. David Beckham is awful b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @GlennFranco68: Tech Firm Suing BuzzFeed fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1850118</th>\n",
              "      <td>Everytime im like 'How the fuck I follow Melan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1850119</th>\n",
              "      <td>RT @imgur: The Trump Handshake. https://t.co/R...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1850120</th>\n",
              "      <td>\"Greenspan warns Trump's policies risk inflati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1850121</th>\n",
              "      <td>RT @FasinatingLogic: We must also #INVESTIGATE...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1850122</th>\n",
              "      <td>RT @imgur: The Trump Handshake. https://t.co/R...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1850123 rows √ó 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0767cb9e-e9f7-4ce2-97ea-2b6d46d636d2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0767cb9e-e9f7-4ce2-97ea-2b6d46d636d2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0767cb9e-e9f7-4ce2-97ea-2b6d46d636d2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7b892027-2689-4b60-9e01-c43275e26571\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7b892027-2689-4b60-9e01-c43275e26571')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7b892027-2689-4b60-9e01-c43275e26571 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_data = df['text'].apply(lambda dataset: text_cleaning_pipeline(dataset))"
      ],
      "metadata": {
        "id": "yfYo_KSXKhXb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train-Test Split"
      ],
      "metadata": {
        "id": "mLtrACMQ-yqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df['text']\n",
        "y = df['Sentiment']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "FNtTjuP66exW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TF-IDF Vectorization"
      ],
      "metadata": {
        "id": "ioG3a7hu-38u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "2z9i9oPa6tRR"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training and Evaluation"
      ],
      "metadata": {
        "id": "xPAqH5tG--pg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "model = LogisticRegression()\n",
        "\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48VvlQAk6wQM",
        "outputId": "20db7f35-734d-4236-870f-7172e0a0ee0c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96    248563\n",
            "           1       0.94      0.92      0.93    121462\n",
            "\n",
            "    accuracy                           0.95    370025\n",
            "   macro avg       0.95      0.94      0.95    370025\n",
            "weighted avg       0.95      0.95      0.95    370025\n",
            "\n"
          ]
        }
      ]
    }
  ]
}